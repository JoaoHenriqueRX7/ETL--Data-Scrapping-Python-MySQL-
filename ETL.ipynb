{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Data ETL (Extract, Transform, Load) Project Using Python\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Hello, I'm Jo√£o Henrique. In this project, we'll explore a practical application of Python for an ETL (Extract, Transform, Load) process, focusing on car data. We'll extract information from various file formats, transform it, and load it into a database, showcasing Python's utility in data processing and database operations.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "1. **Data Download and Extraction**:\n",
    "   - Download a zip file containing our data from a remote server.\n",
    "   - Extract the contents, which include CSV, JSON, and XML files.\n",
    "\n",
    "2. **Data Extraction**:\n",
    "   - Use Python's Pandas library and other tools to read data from each file format and create a uniform data structure.\n",
    "\n",
    "3. **Data Transformation**:\n",
    "   - Perform currency conversion from USD to EUR on the extracted data.\n",
    "\n",
    "4. **Data Load**:\n",
    "   - Connect to a MySQL database and load the transformed data.\n",
    "\n",
    "4. **Query data**:\n",
    "   - Query the data from the Database.\n",
    "\n",
    "## Technical Aspects\n",
    "\n",
    "- This project utilizes Python libraries like `requests`, `pandas`, `xml.etree.ElementTree`, and `mysql.connector`.\n",
    "- For currency conversion, web scraping techniques are used to retrieve the latest USD to EUR conversion rate.\n",
    "\n",
    "## Execution Guide\n",
    "\n",
    "- **Setting Up**:\n",
    "  - Ensure required Python libraries are installed.\n",
    "  - Download your Kaggle credentials and replace the placeholder in the code.\n",
    "\n",
    "- **Running the Code**:\n",
    "  - The script is divided into functions, each handling a part of the ETL process.\n",
    "  - Run the entire script to see the ETL process or step through each function individually.\n",
    "\n",
    "- **Logging**:\n",
    "  - Logs are written to `log_file.txt`, useful for debugging or tracking.\n",
    "\n",
    "---\n",
    "\n",
    "**Let's dive into Python's versatility in data processing, from extraction and transformation to database management!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "- Python (version 3.11.3): The Python programming language itself.\n",
    "- MySQL (version 8.0.34): The database workbench\n",
    "\n",
    "To run this notebook, you need the following Python libraries:\n",
    "\n",
    "- pandas (version 2.0.3): A popular data manipulation and analysis library.\n",
    "- requests (version 2.31.0): A library for making HTTP requests, commonly used for web scraping and API interactions.\n",
    "- xml.etree.ElementTree (version 1.3.0): A module for parsing and manipulating XML documents.\n",
    "- mysql.connector (version 8.2.0): A library for connecting to MySQL databases and performing database operations.\n",
    "- glob: A module for searching and working with file paths using wildcard patterns.\n",
    "- datetime: A module for working with date and time data.\n",
    "- zipfile: A module for creating and extracting zip archives.\n",
    "- json: for return request in json\n",
    "\n",
    "\n",
    "You can install these libraries using pip:\n",
    "\n",
    "    pip install requests zipfile36 pandas glob2 mysql-connector-python datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET \n",
    "import glob \n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants Definition\n",
    "\n",
    "In this notebook, we define a set of constants that are crucial for the smooth execution of our script. These constants primarily involve paths and file names required for the data extraction, transformation, and loading process.\n",
    "\n",
    "## Description of Constants\n",
    "\n",
    "- `URL`: The URL of the data source. This is the link to the zip file containing our datasets in various formats (CSV, JSON, XML).\n",
    "- `FILE_NAME`: The name of the file obtained from the URL. This helps us to dynamically assign the file name based on the URL.\n",
    "- `ZIP_FILE_PATH`: The path to the zip file that will be downloaded. We name the zip file as 'datasource.zip'.\n",
    "- `EXTRACTION_PATH`: The directory path where the contents of the zip file will be extracted. It is set to the current directory denoted by '.'.\n",
    "- `LOG_FILE`: The name of the file where we will log the operations and errors during the script's execution. It is essential for tracking the progress and debugging.\n",
    "- `TARGET_FILE`: The name of the final output file where the transformed data will be stored. In this case, it is named 'car_data.csv'.\n",
    "\n",
    "By defining these constants at the beginning, we ensure that our script remains organized and easier to manage. It also allows for easier adjustments should there be changes in file paths or names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0221EN-SkillsNetwork/labs/module%206/Lab%20-%20Extract%20Transform%20Load/data/datasource.zip\"\n",
    "FILE_NAME = URL.split('/')[-1]\n",
    "ZIP_FILE_PATH = 'datasource.zip'  # The name of the zip file\n",
    "EXTRACTION_PATH = '.'  # Current directory\n",
    "LOG_FILE = \"log_file.txt\"\n",
    "TARGET_FILE = \"car_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(message): \n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    with open(LOG_FILE,\"a\") as f: \n",
    "        f.write(timestamp + ',' + message + '\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and Extracting Data\n",
    "\n",
    "The `download` function is designed to perform two main tasks: downloading the dataset from a provided URL and extracting the contents of the downloaded zip file.\n",
    "\n",
    "## Function Description\n",
    "\n",
    "1. **Downloading the Dataset:**\n",
    "   - The function makes a GET request to the URL specified in the `URL` constant.\n",
    "   - If the request is successful (`status code 200`), the content of the response, which is the dataset in a zip format, is written to a file named as specified in `FILE_NAME`.\n",
    "   - If the request fails, it prints an error message along with the failed status code.\n",
    "\n",
    "2. **Extracting the Zip File:**\n",
    "   - After downloading, the function unzips the file located at `ZIP_FILE_PATH`.\n",
    "   - The contents of the zip file are extracted to the directory specified in `EXTRACTION_PATH`.\n",
    "   - A confirmation message is printed indicating successful extraction and the location of the extracted files.\n",
    "\n",
    "This function is an integral part of the data pipeline, ensuring that the required data is available and accessible for the subsequent extraction, transformation, and loading processes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the file\n",
    "def download():\n",
    "    response = requests.get(URL)\n",
    "    if response.status_code == 200:\n",
    "        with open(FILE_NAME, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"File downloaded successfully and saved as {FILE_NAME}\")\n",
    "    else:\n",
    "        print(f\"Failed to download file. Status code: {response.status_code}\")\n",
    "    \n",
    "    # Unzipping the file\n",
    "    with zipfile.ZipFile(ZIP_FILE_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACTION_PATH)\n",
    "        print(f\"Files extracted to project path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File downloaded successfully and saved as datasource.zip\n",
      "Files extracted to project path\n"
     ]
    }
   ],
   "source": [
    "# Download the data\n",
    "try:\n",
    "    download()\n",
    "    log_progress(\"Data downloaded successfully\")\n",
    "except Exception as e:\n",
    "    log_progress(f\"Error in download: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction Functions\n",
    "\n",
    "In this section, we define functions to extract data from different file formats: CSV, JSON, and XML. These functions are crucial for retrieving and formatting the data needed for further processing.\n",
    "\n",
    "## `extract_from_csv` Function\n",
    "- **Purpose:** This function reads data from a CSV file and converts it into a Pandas DataFrame.\n",
    "- **Input Parameter:** `file_to_process` - The path to the CSV file.\n",
    "- **Process:** The function utilizes `pandas.read_csv` to read the CSV file into a DataFrame.\n",
    "- **Return:** A DataFrame containing data from the CSV file.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_csv(file_to_process):\n",
    "    dataframe = pd.read_csv(file_to_process)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `extract_from_json` Function\n",
    "- **Purpose:** Designed to extract data from a JSON file.\n",
    "- **Input Parameter:** `file_to_process` - The path to the JSON file.\n",
    "- **Process:** It uses `pandas.read_json` with `lines=True` to handle the JSON file correctly.\n",
    "- **Return:** A DataFrame with data from the JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_json(file_to_process):\n",
    "    dataframe = pd.read_json(file_to_process,lines=True)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `extract_from_xml` Function\n",
    "- **Purpose:** Extracts data from an XML file.\n",
    "- **Input Parameter:** `file_to_process` - The path to the XML file.\n",
    "- **Process:**\n",
    "  - Initializes an empty DataFrame with predefined columns: `[\"car_model\",\"year_of_manufacture\",\"price\",\"fuel\"]`.\n",
    "  - Parses the XML file and iterates over each element (car) to extract relevant information.\n",
    "  - For each car, it finds and converts `car_model`, `year_of_manufacture`, `price`, and `fuel` to their respective data types.\n",
    "  - Appends this data as a new row to the DataFrame.\n",
    "- **Return:** A DataFrame with the aggregated data from the XML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_xml(file_to_process):\n",
    "        dataframe = pd.DataFrame(columns=[\"car_model\",\"year_of_manufacture\",\"price\",\"fuel\"])\n",
    "        tree = ET.parse(file_to_process)\n",
    "        root = tree.getroot() \n",
    "        for car in root:\n",
    "            car_model = car.find(\"car_model\").text\n",
    "            year_of_manufacture = int(car.find(\"year_of_manufacture\").text)\n",
    "            price = float(car.find(\"price\").text)\n",
    "            fuel = car.find(\"fuel\").text\n",
    "            dataframe = pd.concat([dataframe, pd.DataFrame([{\"car_model\":car_model,\n",
    "                                                            \"year_of_manufacture\":year_of_manufacture,\n",
    "                                                            \"price\":price,\n",
    "                                                            \"fuel\":fuel}])], ignore_index=True)\n",
    "        return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are designed to handle different data formats efficiently, making the extraction process versatile and robust for varied data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Data Extraction Function: `extract`\n",
    "\n",
    "This function is the centerpiece for the data extraction process in our ETL (Extract, Transform, Load) pipeline. Its role is to orchestrate the extraction of data from various file formats and consolidate it into a single DataFrame.\n",
    "\n",
    "## Function Overview\n",
    "\n",
    "- **Purpose:** To aggregate data from multiple files of different formats (CSV, JSON, XML) into a unified Pandas DataFrame.\n",
    "- **Process:**\n",
    "  1. **Initialization:**\n",
    "     - Creates an empty DataFrame `extracted_data` with predefined columns: `['car_model', 'year_of_manufacture', 'price', 'fuel']`.\n",
    "  2. **Processing CSV Files:**\n",
    "     - Iterates over all CSV files in the current directory (identified by the `*.csv` pattern).\n",
    "     - For each CSV file, it calls `extract_from_csv` and concatenates the returned DataFrame to `extracted_data`.\n",
    "  3. **Processing JSON Files:**\n",
    "     - Iterates over all JSON files (identified by the `*.json` pattern).\n",
    "     - Invokes `extract_from_json` for each JSON file and appends the result to `extracted_data`.\n",
    "  4. **Processing XML Files:**\n",
    "     - Goes through all XML files (marked by `*.xml`).\n",
    "     - Each XML file's data, extracted through `extract_from_xml`, is merged into `extracted_data`.\n",
    "- **Return:** The function returns the `extracted_data` DataFrame, which contains combined data from all processed files.\n",
    "\n",
    "## Usage\n",
    "\n",
    "Call this function to execute the initial step of the ETL pipeline, ensuring all necessary data from various sources is gathered in a structured and consistent format. This aggregated data is then ready for the subsequent 'Transform' and 'Load' stages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    #Create an empty dataframe with the indexes\n",
    "    extracted_data = pd.DataFrame(columns=['car_model','year_of_manufacture','price','fuel'])\n",
    "    \n",
    "    # process all csv files \n",
    "    for csv_file in glob.glob('*.csv'):\n",
    "        extracted_data = pd.concat([extracted_data,pd.DataFrame(extract_from_csv(csv_file))], ignore_index=True)\n",
    "        \n",
    "    # process all json files \n",
    "    for json_file in glob.glob('*.json'):\n",
    "        extracted_data = pd.concat([extracted_data,pd.DataFrame(extract_from_json(json_file))], ignore_index=True)\n",
    "        \n",
    "    # process all xml files \n",
    "    for xml_file in glob.glob('*.xml'):\n",
    "        extracted_data = pd.concat([extracted_data,pd.DataFrame(extract_from_xml(xml_file))], ignore_index=True)\n",
    "\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data\n",
    "extracted_data = extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        car_model year_of_manufacture         price    fuel\n",
      "0            ritz                2014   5000.000000  Petrol\n",
      "1             sx4                2013   7089.552239  Diesel\n",
      "2            ciaz                2017  10820.895522  Petrol\n",
      "3         wagon r                2011   4253.731343  Petrol\n",
      "4           swift                2014   6865.671642  Diesel\n",
      "..            ...                 ...           ...     ...\n",
      "85          camry                2006   3731.343284  Petrol\n",
      "86   land cruiser                2010  52238.805970  Diesel\n",
      "87  corolla altis                2012   8805.970149  Petrol\n",
      "88     etios liva                2013   5149.253731  Petrol\n",
      "89        etios g                2014   7089.552239  Petrol\n",
      "\n",
      "[90 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(extracted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Currency Conversion Function: `get_EUR`\n",
    "\n",
    "This function is responsible for fetching the current exchange rate between the US Dollar (USD) and the Euro (EUR). It plays a crucial role in the 'Transform' stage of our ETL pipeline, ensuring that the pricing data is standardized in a single currency for consistency and ease of analysis.\n",
    "\n",
    "## Function Overview\n",
    "\n",
    "- **Purpose:** To obtain the latest USD to EUR exchange rate from the CoinGecko API.\n",
    "- **Process:**\n",
    "  1. **API Request:**\n",
    "     - Sends a GET request to the CoinGecko API's `/simple/price` endpoint.\n",
    "     - Requests the price of 1 USD in EUR (`'ids': 'usd'` and `'vs_currencies': 'eur'`).\n",
    "  2. **Response Handling:**\n",
    "     - Checks if the API response status is 200 (OK).\n",
    "     - Parses the JSON response to extract the exchange rate.\n",
    "  3. **Data Extraction:**\n",
    "     - Retrieves the USD to EUR exchange rate from the response data.\n",
    "     - Returns the exchange rate if found.\n",
    "     - Prints an error message if the USD data is not found or if the API request fails.\n",
    "\n",
    "## Usage\n",
    "\n",
    "Use this function to dynamically fetch the current exchange rate between USD and EUR. This rate can then be applied to convert any USD values to EUR in the dataset, ensuring currency consistency in the transformed data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_EUR():\n",
    "\n",
    "    url = 'https://api.coingecko.com/api/v3/simple/price'\n",
    "    params = {  \n",
    "        'ids': 'usd',  # Request the price of 1 USD in EUR\n",
    "        'vs_currencies': 'eur'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "    \n",
    "    data = response.json()\n",
    "    \n",
    "    USD_to_EUR_rate = data['usd']['eur']  # Access the USD/EUR exchange rate\n",
    "    return USD_to_EUR_rate\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92178"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_EUR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation Function: `transform`\n",
    "\n",
    "The `transform` function is a key part of the data processing pipeline. It takes the extracted data and applies necessary transformations to make it suitable for analysis and storage. A primary task in this function is the conversion of price data from USD to EUR.\n",
    "\n",
    "## Function Overview\n",
    "\n",
    "- **Purpose:** To transform the extracted data for consistency and readiness for the loading stage.\n",
    "- **Process:**\n",
    "  1. **Currency Conversion:**\n",
    "     - Fetches the current USD to EUR exchange rate using the `get_EUR` function.\n",
    "     - Rounds off the price in USD to two decimal places for uniformity.\n",
    "     - Converts the price from USD to EUR using the fetched exchange rate and rounds the result to two decimal places.\n",
    "     - Adds this converted price as a new column `price_EUR` in the DataFrame.\n",
    "  2. **Returning Transformed Data:**\n",
    "     - The function returns the transformed DataFrame with the newly added `price_EUR` column.\n",
    "\n",
    "## Usage\n",
    "\n",
    "This function is used in the 'Transform' phase of the ETL process. After extracting data from various sources, use `transform` to standardize the data format, particularly the pricing information, ensuring that all financial values are represented in a single currency (EUR). This makes the dataset uniform and easier to analyze and store in the subsequent stages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "\n",
    "    USD_to_EUR = get_EUR()\n",
    "    #round to 2 decimals\n",
    "    data['price'] = round(data['price'],2)\n",
    "    \n",
    "    #transform USD to EUR and round\n",
    "    data['price_EUR'] = round(data['price']* float(USD_to_EUR),2)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car_model</th>\n",
       "      <th>year_of_manufacture</th>\n",
       "      <th>price</th>\n",
       "      <th>fuel</th>\n",
       "      <th>price_EUR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ritz</td>\n",
       "      <td>2014</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>4608.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sx4</td>\n",
       "      <td>2013</td>\n",
       "      <td>7089.55</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>6535.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ciaz</td>\n",
       "      <td>2017</td>\n",
       "      <td>10820.90</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>9974.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wagon r</td>\n",
       "      <td>2011</td>\n",
       "      <td>4253.73</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>3921.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>swift</td>\n",
       "      <td>2014</td>\n",
       "      <td>6865.67</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>6328.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>camry</td>\n",
       "      <td>2006</td>\n",
       "      <td>3731.34</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>3439.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>land cruiser</td>\n",
       "      <td>2010</td>\n",
       "      <td>52238.81</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>48152.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>corolla altis</td>\n",
       "      <td>2012</td>\n",
       "      <td>8805.97</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>8117.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>etios liva</td>\n",
       "      <td>2013</td>\n",
       "      <td>5149.25</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>4746.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>etios g</td>\n",
       "      <td>2014</td>\n",
       "      <td>7089.55</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>6535.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        car_model year_of_manufacture     price    fuel  price_EUR\n",
       "0            ritz                2014   5000.00  Petrol    4608.90\n",
       "1             sx4                2013   7089.55  Diesel    6535.01\n",
       "2            ciaz                2017  10820.90  Petrol    9974.49\n",
       "3         wagon r                2011   4253.73  Petrol    3921.00\n",
       "4           swift                2014   6865.67  Diesel    6328.64\n",
       "..            ...                 ...       ...     ...        ...\n",
       "85          camry                2006   3731.34  Petrol    3439.47\n",
       "86   land cruiser                2010  52238.81  Diesel   48152.69\n",
       "87  corolla altis                2012   8805.97  Petrol    8117.17\n",
       "88     etios liva                2013   5149.25  Petrol    4746.48\n",
       "89        etios g                2014   7089.55  Petrol    6535.01\n",
       "\n",
       "[90 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_data = transform(extracted_data)\n",
    "transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Connection Function: `connect_database`\n",
    "\n",
    "The `connect_database` function is a crucial part of the data handling process, particularly in establishing a connection to a MySQL database. This function is essential for both extracting data from and loading data into the database.\n",
    "\n",
    "## Function Overview\n",
    "\n",
    "- **Purpose:** To establish a connection with a MySQL database using provided credentials and port information.\n",
    "- **Inputs:**\n",
    "  1. `host`: The hostname or IP address of the database server.\n",
    "  2. `user`: The username used for authentication with the MySQL server.\n",
    "  3. `password`: The password used for authentication with the MySQL server.\n",
    "  4. `port`: The port number through which to connect to the MySQL server.\n",
    "- **Process:**\n",
    "  - Utilizes the `mysql.connector` library to establish a connection to the MySQL database.\n",
    "  - The function returns a connection object (`mydb`), which can be used for executing queries, inserting data, and other database operations.\n",
    "\n",
    "## Usage\n",
    "\n",
    "This function is vital for any operation that requires interaction with a MySQL database. It is commonly used at the beginning of data extraction and loading processes, allowing for seamless and secure access to the database. The flexibility to specify different host addresses and port numbers makes it versatile for various environments, from local testing to deployment in production systems.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to database\n",
    "def connect_database(host,user,password,port):\n",
    "    \n",
    "    mydb = mysql.connector.connect(\n",
    "        \n",
    "    host=host,\n",
    "    user=user,\n",
    "    password=password,\n",
    "    port=port\n",
    "    \n",
    "    )   \n",
    "    return mydb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mysql.connector.connection_cext.CMySQLConnection at 0x1fab8e2d650>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydb = connect_database('127.0.0.1', 'root', 'password', '6666')\n",
    "mydb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading Function: `load`\n",
    "\n",
    "The `load` function plays a crucial role in the final stage of the ETL (Extract, Transform, Load) process. Its primary responsibility is to load the transformed data into a CSV file and a MySQL database.\n",
    "\n",
    "## Function Overview\n",
    "\n",
    "- **Purpose:** To save the transformed data into a persistable format, ensuring that it is stored for future analysis and retrieval.\n",
    "- **Process:**\n",
    "  1. **Save to CSV:**\n",
    "     - The function first saves the transformed data into a CSV file specified by `target_file`.\n",
    "  2. **Database Interaction:**\n",
    "     - Establishes a cursor for database interaction.\n",
    "     - Converts the pandas DataFrame to a structured array for ease of data insertion.\n",
    "     - Creates a new schema named `car` in the MySQL database if it doesn't already exist.\n",
    "     - Selects the `car` schema for subsequent operations.\n",
    "     - Creates a new table named `car` with appropriate columns (`id`, `car_model`, `year_of_manufacture`, `price`, `price_EUR`, `fuel`) if it doesn't exist.\n",
    "     - Prepares the SQL insert statement (`DML`).\n",
    "  3. **Data Insertion:**\n",
    "     - Iterates over each record in the structured array and executes the insert statement to load data into the `car` table.\n",
    "  4. **Commit and Close:**\n",
    "     - Commits the transaction to save changes to the database.\n",
    "     - Closes the database connection.\n",
    "\n",
    "## Usage\n",
    "\n",
    "This function is essential in the 'Load' phase of the ETL process. After transforming the data, `load` facilitates storing the data both in a CSV file for easy access and in a MySQL database for more structured and complex queries. This dual approach to data storage maximizes the utility and accessibility of the processed data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(target_file,data,mydb):\n",
    "    #load to a csv file\n",
    "    data.to_csv(target_file)\n",
    "    mycursor = mydb.cursor()\n",
    "    \n",
    "    # Convert the DataFrame to a structured array\n",
    "    data_records = data.to_records(index=False)\n",
    "    \n",
    "    # Create schema\n",
    "    mycursor.execute(\"CREATE SCHEMA IF NOT EXISTS `car`\")\n",
    "    \n",
    "    mycursor.execute(\"USE car\")\n",
    "    \n",
    "    #Create a table car if not exists\n",
    "    mycursor.execute(\"\"\"\n",
    "                     CREATE TABLE IF NOT EXISTS car \n",
    "                        (\n",
    "                        id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                        car_model VARCHAR(255),\n",
    "                        year_of_manufacture INT, \n",
    "                        price FLOAT,\n",
    "                        price_EUR FLOAT, \n",
    "                        fuel VARCHAR(45)\n",
    "                        )\n",
    "                    \"\"\")\n",
    "    #make the DML function\n",
    "    DML = \"\"\"INSERT INTO car \n",
    "        (car_model, year_of_manufacture, price, price_EUR, fuel)\n",
    "        VALUES (%s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "    for record in data_records:\n",
    "        VAL = (record.car_model, record.year_of_manufacture, record.price, record.price_EUR, record.fuel)\n",
    "        mycursor.execute(DML, VAL)\n",
    "            \n",
    "    mydb.commit()\n",
    "    mydb.close()\n",
    "    return json.dumps({'rows_inserted': len(data_records)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"rows_inserted\": 90}'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load(TARGET_FILE, transformed_data, mydb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Query Function: `query`\n",
    "\n",
    "The `quey` function is designed to retrieve data from the 'car' table within a MySQL database. This function is instrumental in data retrieval operations, especially for analyzing and processing stored data.\n",
    "\n",
    "## Function Overview\n",
    "\n",
    "- **Purpose:** To instatiate a query and return in a dataframe form.\n",
    "- **Inputs:**\n",
    "  1. `mydb`: A MySQL database connection object, established through the `connect_database` function.\n",
    "  2. `query`: The query in string format, a modular way to make a customized query.\n",
    "- **Process:**\n",
    "  1. **Create Cursor:** Initialize a cursor object using the database connection for executing queries.\n",
    "  2. **Execute Query:** Perform a `SELECT` SQL custom query.\n",
    "  3. **Fetch Data:** Extract all fetched rows using the `fetchall()` method.\n",
    "  4. **Close Resources:** Close both the cursor and the database connection to ensure resource management and prevent memory leaks.\n",
    "- **Output:** Returns the fetched data as a list of tuples, each tuple representing a row from the 'car' table.\n",
    "\n",
    "## Usage\n",
    "\n",
    "This function is primarily used for data analysis and reporting purposes, where data from the 'car' table needs to be extracted for further processing or visualization. It ensures a streamlined approach to data retrieval from the database, abstracting the complexities of SQL queries and cursor management.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(mydb,query):\n",
    "\n",
    "    try:\n",
    "        mycursor = mydb.cursor()\n",
    "        mycursor.execute(\"USE car\")\n",
    "        # Execute the query and convert directly to a DataFrame\n",
    "        dataframe = pd.read_sql_query(query, mydb)\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data: {e}\")\n",
    "\n",
    "    return dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the query yourself!\n",
    "\n",
    "You can know more about querys in my <a href=\"https://balenciagaa.notion.site/SQL-1b15be8f10d74695a8de7bc860292f1b?pvs=73\">SQL tutorial</a> (It's in portuguese right now but i will fix soon): \n",
    "\n",
    "\n",
    "## Query examples:\n",
    "\n",
    "**Retrieve Records with Specific Conditions**\n",
    "\n",
    "`SELECT * FROM car WHERE year_of_manufacture > 2010`\n",
    "\n",
    "**Calculate Average Price**\n",
    "\n",
    "`SELECT AVG(price) AS average_price FROM car`\n",
    "\n",
    "**Group by Fuel Type and AVG price for each type**\n",
    "\n",
    "`SELECT fuel, AVG(price) AS average_price FROM car GROUP BY fuel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Connect to database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = connect_database('127.0.0.1', 'root', '112104', '6666')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Make the query here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joaoh\\AppData\\Local\\Temp\\ipykernel_11092\\2840198487.py:7: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  dataframe = pd.read_sql_query(query, mydb)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>car_model</th>\n",
       "      <th>year_of_manufacture</th>\n",
       "      <th>price</th>\n",
       "      <th>price_EUR</th>\n",
       "      <th>fuel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ritz</td>\n",
       "      <td>2014</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>4608.90</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>sx4</td>\n",
       "      <td>2013</td>\n",
       "      <td>7089.55</td>\n",
       "      <td>6535.01</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>ciaz</td>\n",
       "      <td>2017</td>\n",
       "      <td>10820.90</td>\n",
       "      <td>9974.49</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>wagon r</td>\n",
       "      <td>2011</td>\n",
       "      <td>4253.73</td>\n",
       "      <td>3921.00</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>swift</td>\n",
       "      <td>2014</td>\n",
       "      <td>6865.67</td>\n",
       "      <td>6328.64</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>266</td>\n",
       "      <td>camry</td>\n",
       "      <td>2006</td>\n",
       "      <td>3731.34</td>\n",
       "      <td>3439.47</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>267</td>\n",
       "      <td>land cruiser</td>\n",
       "      <td>2010</td>\n",
       "      <td>52238.80</td>\n",
       "      <td>48152.70</td>\n",
       "      <td>Diesel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>268</td>\n",
       "      <td>corolla altis</td>\n",
       "      <td>2012</td>\n",
       "      <td>8805.97</td>\n",
       "      <td>8117.17</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>269</td>\n",
       "      <td>etios liva</td>\n",
       "      <td>2013</td>\n",
       "      <td>5149.25</td>\n",
       "      <td>4746.48</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>270</td>\n",
       "      <td>etios g</td>\n",
       "      <td>2014</td>\n",
       "      <td>7089.55</td>\n",
       "      <td>6535.01</td>\n",
       "      <td>Petrol</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      car_model  year_of_manufacture     price  price_EUR    fuel\n",
       "0      1           ritz                 2014   5000.00    4608.90  Petrol\n",
       "1      2            sx4                 2013   7089.55    6535.01  Diesel\n",
       "2      3           ciaz                 2017  10820.90    9974.49  Petrol\n",
       "3      4        wagon r                 2011   4253.73    3921.00  Petrol\n",
       "4      5          swift                 2014   6865.67    6328.64  Diesel\n",
       "..   ...            ...                  ...       ...        ...     ...\n",
       "265  266          camry                 2006   3731.34    3439.47  Petrol\n",
       "266  267   land cruiser                 2010  52238.80   48152.70  Diesel\n",
       "267  268  corolla altis                 2012   8805.97    8117.17  Petrol\n",
       "268  269     etios liva                 2013   5149.25    4746.48  Petrol\n",
       "269  270        etios g                 2014   7089.55    6535.01  Petrol\n",
       "\n",
       "[270 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query(mydb,\"SELECT * FROM car\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Close de database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
